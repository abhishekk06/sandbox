{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQJR/4Eb1cvDZViKElrcLo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHP8yI6oDCdZ"
      },
      "outputs": [],
      "source": [
        "!tar -xvf /content/Assignment.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Interview_Coding_Problem_v1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6DryylQDo13",
        "outputId": "1364c0fc-2a72-45b8-e5d1-a5c657dcc21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Interview_Coding_Problem_v1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJtpknPaFEVZ",
        "outputId": "ba671d7e-f67d-4a86-8c2f-f58fa33e58d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-at8b6fik\n",
            "  Running command git clone --filter=blob:none --quiet git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-at8b6fik\n",
            "  fatal: unable to connect to github.com:\n",
            "  github.com[0: 140.82.114.4]: errno=Connection timed out\n",
            "\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet git:\u001b[0m\u001b[32m/\u001b[0m\u001b[32m/github.com/andreinechaev/\u001b[0m\u001b[32mnvcc4jupyter.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-at8b6fik\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet git:\u001b[0m\u001b[32m/\u001b[0m\u001b[32m/github.com/andreinechaev/\u001b[0m\u001b[32mnvcc4jupyter.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-at8b6fik\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P2ocNJzDuSr",
        "outputId": "07c7c0f6-9409-49a0-d615-cbefd784715b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make dirs\n",
            "make[1]: Entering directory '/content/Interview_Coding_Problem_v1.2'\n",
            "if [ ! -d bin ]; then mkdir -p bin; fi\n",
            "if [ ! -d obj ]; then mkdir -p obj; fi\n",
            "make[1]: Leaving directory '/content/Interview_Coding_Problem_v1.2'\n",
            "make bin/interview_problem.exe\n",
            "make[1]: Entering directory '/content/Interview_Coding_Problem_v1.2'\n",
            "/usr/local/cuda/bin/nvcc -O3 -g -std=c++14 --expt-relaxed-constexpr -gencode=arch=compute_35,code=sm_35 -gencode=arch=compute_50,code=sm_50 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -Isrc -I/usr/local/cuda/include -o obj/device_tensor.o -c src/device_tensor.cu\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'sm_35', and 'sm_37' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\u001b[01m\u001b[0m\u001b[01msrc/utils.cuh(11)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mstderr\u001b[0m\" is undefined\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01msrc/utils.cuh(11)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mfprintf\u001b[0m\" is undefined\n",
            "\n",
            "2 errors detected in the compilation of \"src/device_tensor.cu\".\n",
            "make[1]: *** [Makefile:36: obj/device_tensor.o] Error 2\n",
            "make[1]: Leaving directory '/content/Interview_Coding_Problem_v1.2'\n",
            "make: *** [Makefile:26: all] Error 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iEDf9fJD9fp",
        "outputId": "9b2e561c-0611-43fa-976a-9a7b5a0ea6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 20 21:51:00 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}